# ğŸ§  AI Detector â€“ Hybrid BERT & Stylometric Analysis

## ğŸ“Œ Overview
Questo progetto implementa un **sistema end-to-end per il rilevamento di testi generati da Intelligenza Artificiale**, combinando modelli NLP moderni e tecniche di analisi stilometrica.  
Lâ€™obiettivo Ã¨ distinguere testi **scritti da esseri umani** da testi **generati da modelli AI**, adottando un approccio sia **predittivo** sia **interpretabile**.

Il sistema Ã¨ stato progettato come applicazione **full-stack containerizzata**, includendo backend AI, frontend web e orchestrazione tramite Docker.

---

## ğŸ—ï¸ Architettura del Sistema

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” REST API â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ React UI â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚ FastAPI ML â”‚
â”‚ Frontend â”‚ â”‚ Backend â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Modelli ML â”‚
â”‚ BERT (.pth) â”‚
â”‚ Signature (.pkl) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


- **Frontend**: React + TailwindCSS  
- **Backend**: Python + FastAPI  
- **Modelli**: BERT + feature stilometriche  
- **Deployment**: Docker & Docker Compose  

---

## ğŸ“ Struttura del Progetto

bert_ai_detector/
â”‚
â”œâ”€â”€ app.py # Backend FastAPI
â”œâ”€â”€ requirements.txt # Dipendenze Python
â”œâ”€â”€ Dockerfile # Backend container
â”‚
â”œâ”€â”€ react-app/ # Frontend React
â”‚ â”œâ”€â”€ Dockerfile
â”‚ â”œâ”€â”€ src/
â”‚ â”‚ â””â”€â”€ components/
â”‚ â”‚ â””â”€â”€ AIDetectorInterface.jsx
â”‚ â””â”€â”€ ...
â”‚
â”œâ”€â”€ pth/ # Modelli deep learning
â”‚ â””â”€â”€ best_bert.pth
â”‚
â”œâ”€â”€ pkl/ # Modelli ML / signature
â”œâ”€â”€ txt/ # File di supporto
â”‚
â”œâ”€â”€ *.ipynb # Notebook (EDA, training, analisi)
â”œâ”€â”€ *.csv # Dataset
â”‚
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md


I notebook Jupyter sono volutamente esclusi dai container per separare la fase di **training** da quella di **inference**.

---

## ğŸ”¬ Metodologia

### 1ï¸âƒ£ Exploratory Data Analysis (EDA)
- Analisi statistica dei testi AI vs Human
- Studio di lunghezza, variabilitÃ  e struttura
- Supporto alle decisioni di feature engineering

### 2ï¸âƒ£ Signature Stilometriche
- DiversitÃ  lessicale
- RipetitivitÃ  strutturale
- Burstiness
- Lunghezza media delle frasi

Queste feature forniscono un livello di **interpretabilitÃ ** complementare ai modelli deep learning.

### 3ï¸âƒ£ Modello Ibrido (BERT + Feature Stilometriche)
- Embedding contestuali ottenuti tramite BERT
- Integrazione con feature linguistiche manuali
- Migliore robustezza e generalizzazione rispetto ad approcci singoli

---

## âš™ï¸ Backend â€“ FastAPI

Il backend espone unâ€™API REST per lâ€™analisi dei testi.

### Endpoint
`POST /analyze`

### Input
```json
{
  "text": "Testo da analizzare"
}

## Output
{
  "isAI": true,
  "confidence": 87.3,
  "metrics": {
    "lexical_diversity": 0.42,
    "burstiness": 3.1,
    "avg_sentence_length": 18.7
  }
}

## ğŸ¨ Frontend â€“ React App

Il frontend fornisce unâ€™interfaccia web interattiva per:

inserimento del testo

validazione dellâ€™input

visualizzazione dei risultati e delle metriche

comunicazione diretta con il backend tramite REST API

## ğŸ³ Containerizzazione con Docker

Il sistema Ã¨ completamente containerizzato tramite Docker Compose, che orchestra:

backend AI (FastAPI + modelli ML)

frontend React

Avvio del progetto
docker-compose build
docker-compose up

| Servizio |  | Descrizione     |
| -------- |  | --------------- |
| Backend  |  | API AI Detector |
| Frontend |  | Interfaccia Web |

La comunicazione tra frontend e backend avviene tramite service name Docker, garantendo portabilitÃ  e riproducibilitÃ .

 ## ğŸ“ Scelte Progettuali

Separazione tra training e inference

Approccio ibrido per bilanciare performance e interpretabilitÃ 

Containerizzazione per:

riproducibilitÃ  degli esperimenti

isolamento dellâ€™ambiente

semplicitÃ  di deploy

Interfaccia grafica come strumento di analisi e non solo demo

## âš ï¸ Limiti e Sviluppi Futuri

Generalizzazione rispetto a modelli AI futuri

Integrazione del supporto GPU (CUDA)

Valutazione cross-domain

Logging e monitoring delle predizioni

Supporto per analisi batch

## ğŸ‘¤ Autore

Progetto sviluppato come lavoro accademico nellâ€™ambito di Machine Learning e Natural Language Processing.

## ğŸ Conclusione

Il progetto dimostra come sia possibile costruire un AI Detector moderno e completo, combinando:

analisi statistica

modelli deep learning

interpretabilitÃ  linguistica

ingegneria del software

Il risultato Ã¨ un sistema modulare, riproducibile e pronto al deploy.
