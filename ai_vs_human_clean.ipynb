{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98048d5d",
   "metadata": {},
   "source": [
    "# Analisi AI vs Human"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9658839f",
   "metadata": {},
   "source": [
    "## import delle librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9753771c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\rosy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~illow (c:\\Users\\Rosy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~illow (c:\\Users\\Rosy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~illow (c:\\Users\\Rosy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3263b6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "906f0f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b93dc1",
   "metadata": {},
   "source": [
    "## caricamento del dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b867758e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. pulizia del dataset\n",
      "dataset caricato: 500 righe, 12 colonne\n"
     ]
    }
   ],
   "source": [
    "# caricare il dataset \n",
    "df = pd.read_csv(\"ai_vs_human_dataset_medium.csv\")\n",
    "print(\"1. pulizia del dataset\")\n",
    "print(f\"dataset caricato: {df.shape[0]} righe, {df.shape[1]} colonne\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "21df4ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   id                500 non-null    int64  \n",
      " 1   label             500 non-null    object \n",
      " 2   topic             500 non-null    object \n",
      " 3   text              500 non-null    object \n",
      " 4   length_chars      500 non-null    int64  \n",
      " 5   length_words      500 non-null    int64  \n",
      " 6   quality_score     500 non-null    float64\n",
      " 7   sentiment         500 non-null    float64\n",
      " 8   source_detail     500 non-null    object \n",
      " 9   timestamp         500 non-null    object \n",
      " 10  plagiarism_score  500 non-null    float64\n",
      " 11  notes             157 non-null    object \n",
      "dtypes: float64(3), int64(3), object(6)\n",
      "memory usage: 47.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>length_chars</th>\n",
       "      <th>length_words</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>plagiarism_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.00000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>250.500000</td>\n",
       "      <td>115.152000</td>\n",
       "      <td>16.79800</td>\n",
       "      <td>3.502340</td>\n",
       "      <td>0.161240</td>\n",
       "      <td>0.124510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>144.481833</td>\n",
       "      <td>39.208973</td>\n",
       "      <td>5.83449</td>\n",
       "      <td>0.900641</td>\n",
       "      <td>0.416834</td>\n",
       "      <td>0.095412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>-0.590000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>125.750000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>13.00000</td>\n",
       "      <td>2.847500</td>\n",
       "      <td>-0.170000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>250.500000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>3.540000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.104500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>375.250000</td>\n",
       "      <td>133.250000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>4.240000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.171500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>41.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.349000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  length_chars  length_words  quality_score   sentiment  \\\n",
       "count  500.000000    500.000000     500.00000     500.000000  500.000000   \n",
       "mean   250.500000    115.152000      16.79800       3.502340    0.161240   \n",
       "std    144.481833     39.208973       5.83449       0.900641    0.416834   \n",
       "min      1.000000     65.000000       9.00000       1.500000   -0.590000   \n",
       "25%    125.750000     87.000000      13.00000       2.847500   -0.170000   \n",
       "50%    250.500000    103.000000      14.00000       3.540000    0.190000   \n",
       "75%    375.250000    133.250000      20.00000       4.240000    0.490000   \n",
       "max    500.000000    280.000000      41.00000       5.000000    0.900000   \n",
       "\n",
       "       plagiarism_score  \n",
       "count        500.000000  \n",
       "mean           0.124510  \n",
       "std            0.095412  \n",
       "min            0.000000  \n",
       "25%            0.050000  \n",
       "50%            0.104500  \n",
       "75%            0.171500  \n",
       "max            0.349000  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# panoramica dei dati \n",
    "df.head()\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0895fec3",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b17d2be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2. Pulizia del dataset mirata\n"
     ]
    }
   ],
   "source": [
    "print(\" 2. Pulizia del dataset mirata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e5194cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Questa funzione serve a pulire e normalizzare il testo prima di qualsiasi analisi NLP.\n",
      "Obiettivo principale: rimuovere elementi che non portano informazione stilistica o semantica \n",
      "ma potrebbero introdurre rumore o bias nel modello. In particolare:\n",
      "1. Rimuove il carattere \"|\" usato come marker interno o separatore nei dati.\n",
      "2. Elimina frasi boilerplate tipiche generate da AI (es. \"Analysis indicates that…\"), \n",
      "   che potrebbero creare un data leakage se il modello le imparasse come scorciatoia.\n",
      "3. Normalizza spazi, newline e tabulazioni, riducendo il testo a un formato uniforme,\n",
      "   pronto per tokenizzazione, feature extraction e modeling.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comment = \"\"\"\n",
    "Questa funzione serve a pulire e normalizzare il testo prima di qualsiasi analisi NLP.\n",
    "Obiettivo principale: rimuovere elementi che non portano informazione stilistica o semantica \n",
    "ma potrebbero introdurre rumore o bias nel modello. In particolare:\n",
    "1. Rimuove il carattere \"|\" usato come marker interno o separatore nei dati.\n",
    "2. Elimina frasi boilerplate tipiche generate da AI (es. \"Analysis indicates that…\"), \n",
    "   che potrebbero creare un data leakage se il modello le imparasse come scorciatoia.\n",
    "3. Normalizza spazi, newline e tabulazioni, riducendo il testo a un formato uniforme,\n",
    "   pronto per tokenizzazione, feature extraction e modeling.\n",
    "\"\"\"\n",
    "\n",
    "print(comment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ab12023e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Colonna 'text' pulita in 'text_cleaned' (rimozione marker e boilerplate AI).\n"
     ]
    }
   ],
   "source": [
    "def clean_text_for_nlp(text):\n",
    "    # 1. Rimozione marker di fonte interna e rumore tipico dell'AI\n",
    "    text = re.sub(r'\\|', '', text)\n",
    "    # 2. Rimozione boilerplate (frasi standard che l'AI usa per iniziare)\n",
    "    boilerplate_patterns = [\n",
    "        r'^Analysis indicates that\\s*', r'^The following summary on\\s*', \n",
    "        r'^This article discusses\\s*', r'^As someone who follows\\s*', \n",
    "        r'^I recently experienced\\s*', r'^In my experience,\\s*',\n",
    "        r'^Based on the data,\\s*' # Aggiungiamo un pattern comune\n",
    "    ]\n",
    "    for pattern in boilerplate_patterns:\n",
    "        text = re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # 3. Normalizzazione: rimuove newline, tabulazioni e doppi spazi\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df['text_cleaned'] = df['text'].apply(clean_text_for_nlp)\n",
    "print(\" - Colonna 'text' pulita in 'text_cleaned' (rimozione marker e boilerplate AI).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "59453ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Questa funzione pulisce il testo rimuovendo simboli e caratteri indesiderati.\n",
      "    In particolare:\n",
      "    1. Rimuove tutte le emoji presenti nel testo usando il modulo `emoji`.\n",
      "    2. Elimina qualsiasi carattere che non sia una lettera (a-z, A-Z), numero (0-9), \n",
      "       spazio o punteggiatura base (.,!?) tramite espressione regolare.\n",
      "    3. Restituisce il testo \"pulito\", pronto per analisi NLP, tokenizzazione o feature extraction.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comment = \"\"\"\n",
    "Questa funzione pulisce il testo rimuovendo simboli e caratteri indesiderati.\n",
    "    In particolare:\n",
    "    1. Rimuove tutte le emoji presenti nel testo usando il modulo `emoji`.\n",
    "    2. Elimina qualsiasi carattere che non sia una lettera (a-z, A-Z), numero (0-9), \n",
    "       spazio o punteggiatura base (.,!?) tramite espressione regolare.\n",
    "    3. Restituisce il testo \"pulito\", pronto per analisi NLP, tokenizzazione o feature extraction.\n",
    "\"\"\"\n",
    "\n",
    "print(comment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e61fa84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji \n",
    "\n",
    "def remove_special_chars(text):\n",
    "    text = emoji.replace_emoji(text, replace='')\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s.,!?]', '', text)\n",
    "    return text\n",
    "\n",
    "df['text_cleaned'] = df['text_cleaned'].apply(remove_special_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "72dad35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Questa sezione normalizza ulteriormente il testo e crea versioni standardizzate \n",
      "per l'analisi NLP. In particolare:\n",
      "\n",
      "1. `text_cleaned`:\n",
      "   - Mantiene le maiuscole originali.\n",
      "   - Rimuove spazi iniziali e finali con `.str.strip()`.\n",
      "\n",
      "2. `text_cleaned_lower`:\n",
      "   - Converte tutto il testo in minuscolo usando `.str.lower()`.\n",
      "   - Utile per NLP quando si vogliono confrontare parole senza distinzione tra maiuscole/minuscole.\n",
      "\n",
      "3. Rimozione spazi multipli e newline:\n",
      "   - `re.sub(r'\\s+', '', x)` elimina spazi multipli e newline all'interno del testo.\n",
      "\n",
      "4. Riduzione punteggiatura ripetuta:\n",
      "   - `re.sub(r'([.,!?])\u0001+', r'\u0001', x)` sostituisce sequenze di punteggiatura ripetuta \n",
      "     (es. \"!!!\" o \"..\") con un singolo carattere.\n",
      "\n",
      "Obiettivo generale: avere un testo **uniforme, pulito e coerente** pronto per \n",
      "tokenizzazione, feature extraction o modeling.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\Rosy\\AppData\\Local\\Temp\\ipykernel_10316\\3672646691.py:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  comment = \"\"\"\n"
     ]
    }
   ],
   "source": [
    "comment = \"\"\"\n",
    "Questa sezione normalizza ulteriormente il testo e crea versioni standardizzate \n",
    "per l'analisi NLP. In particolare:\n",
    "\n",
    "1. `text_cleaned`:\n",
    "   - Mantiene le maiuscole originali.\n",
    "   - Rimuove spazi iniziali e finali con `.str.strip()`.\n",
    "   \n",
    "2. `text_cleaned_lower`:\n",
    "   - Converte tutto il testo in minuscolo usando `.str.lower()`.\n",
    "   - Utile per NLP quando si vogliono confrontare parole senza distinzione tra maiuscole/minuscole.\n",
    "\n",
    "3. Rimozione spazi multipli e newline:\n",
    "   - `re.sub(r'\\s+', '', x)` elimina spazi multipli e newline all'interno del testo.\n",
    "\n",
    "4. Riduzione punteggiatura ripetuta:\n",
    "   - `re.sub(r'([.,!?])\\1+', r'\\1', x)` sostituisce sequenze di punteggiatura ripetuta \n",
    "     (es. \"!!!\" o \"..\") con un singolo carattere.\n",
    "\n",
    "Obiettivo generale: avere un testo **uniforme, pulito e coerente** pronto per \n",
    "tokenizzazione, feature extraction o modeling.\n",
    "\"\"\"\n",
    "\n",
    "print(comment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "24ba7589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_cleaned - preserva maiuscole\n",
      "text_cleaned_lower - lowercase\n"
     ]
    }
   ],
   "source": [
    "# lowercase \n",
    "df['text_cleaned'] = df['text_cleaned'].str.strip() \n",
    "df['text_cleaned_lower'] = df['text_cleaned'].str.lower() \n",
    "\n",
    "print(\"text_cleaned - preserva maiuscole\")\n",
    "print(\"text_cleaned_lower - lowercase\")\n",
    "\n",
    "df['text_cleaned'] = df['text_cleaned'].apply(lambda x: re.sub(r'\\s+', '', x))\n",
    "df['text_cleaned'] = df['text_cleaned'].apply(lambda x: re.sub(r'([.,!?])\\1+', r'\\1', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79da2bf2",
   "metadata": {},
   "source": [
    "## Pulizia mirata per pattern AI \"sospetti\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "324a37d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Engineering: Rilevamento pattern tipici di testo generato da AI\n",
      "\n",
      "1. `ai_patterns_detect`:\n",
      "   - Lista di frasi e pattern linguistici tipici che compaiono frequentemente nei testi AI.\n",
      "   - Esempi: \"analysis indicates\", \"research suggests\", \"the following summary\", ecc.\n",
      "\n",
      "2. Funzione `count_ai_patterns(text)`:\n",
      "   - Converte il testo in minuscolo (`text.lower()`) per confronti case-insensitive.\n",
      "   - Conta quante volte ciascun pattern della lista appare nel testo.\n",
      "   - Restituisce un numero intero: il totale dei pattern trovati.\n",
      "\n",
      "3. Applicazione al DataFrame:\n",
      "   - Crea la colonna `ai_pattern_count` che contiene, per ogni testo, il numero di pattern tipici AI.\n",
      "   - Questa feature può essere utile per analisi esplorativa o come segnale di AI, \n",
      "     ma va usata con cautela nel modello finale per evitare **data leakage**.\n",
      "\n",
      "4. Output informativo:\n",
      "   - Stampa la media dei pattern AI nei testi etichettati come AI.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comment = \"\"\"\n",
    "Feature Engineering: Rilevamento pattern tipici di testo generato da AI\n",
    "\n",
    "1. `ai_patterns_detect`:\n",
    "   - Lista di frasi e pattern linguistici tipici che compaiono frequentemente nei testi AI.\n",
    "   - Esempi: \"analysis indicates\", \"research suggests\", \"the following summary\", ecc.\n",
    "\n",
    "2. Funzione `count_ai_patterns(text)`:\n",
    "   - Converte il testo in minuscolo (`text.lower()`) per confronti case-insensitive.\n",
    "   - Conta quante volte ciascun pattern della lista appare nel testo.\n",
    "   - Restituisce un numero intero: il totale dei pattern trovati.\n",
    "\n",
    "3. Applicazione al DataFrame:\n",
    "   - Crea la colonna `ai_pattern_count` che contiene, per ogni testo, il numero di pattern tipici AI.\n",
    "   - Questa feature può essere utile per analisi esplorativa o come segnale di AI, \n",
    "     ma va usata con cautela nel modello finale per evitare **data leakage**.\n",
    "\n",
    "4. Output informativo:\n",
    "   - Stampa la media dei pattern AI nei testi etichettati come AI.\n",
    "\"\"\"\n",
    "\n",
    "print(comment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1fdccecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nella colonna ai_pattern_count AI avg: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering: AI \n",
    "ai_patterns_detect = [\n",
    "    'community response', 'research suggests', 'according to the data',\n",
    "    'analysis indicates', 'this article discusses', 'the following summary'\n",
    "]\n",
    "\n",
    "def count_ai_patterns(text):\n",
    "    text_lower = text.lower()\n",
    "    return sum([1 for pattern in ai_patterns_detect if pattern in text_lower])\n",
    "    \n",
    "df['ai_pattern_count'] = df['text_cleaned'].apply(count_ai_patterns)\n",
    "print(f\" nella colonna ai_pattern_count AI avg: {df[df['label'] == 'ai']['ai_pattern_count'].mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df736f8",
   "metadata": {},
   "source": [
    "## Gestione dei valori mancanti mirata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "17f3519d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Gestione dei valori mancanti\n"
     ]
    }
   ],
   "source": [
    "print(\"3. Gestione dei valori mancanti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e72a2222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gestione della colonna 'notes' (variabile categorica)\n",
      "\n",
      "1. Imputazione dei valori mancanti o vuoti:\n",
      "   - Sostituisce le celle vuote (`''`) e i valori NaN con la stringa 'no_tone'.\n",
      "   - Questo garantisce che tutti i record abbiano un valore valido nella colonna.\n",
      "\n",
      "2. Conversione a tipo categorico:\n",
      "   - Trasforma la colonna in tipo `category`, utile per:\n",
      "     • Ridurre l’uso di memoria\n",
      "     • Facilitare l’uso in modelli di machine learning che gestiscono feature categoriche\n",
      "\n",
      "3. Output informativo:\n",
      "   - Stampa un messaggio che conferma l’imputazione e la conversione a categoria.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comment = \"\"\"\n",
    "Gestione della colonna 'notes' (variabile categorica)\n",
    "\n",
    "1. Imputazione dei valori mancanti o vuoti:\n",
    "   - Sostituisce le celle vuote (`''`) e i valori NaN con la stringa 'no_tone'.\n",
    "   - Questo garantisce che tutti i record abbiano un valore valido nella colonna.\n",
    "\n",
    "2. Conversione a tipo categorico:\n",
    "   - Trasforma la colonna in tipo `category`, utile per:\n",
    "     • Ridurre l’uso di memoria\n",
    "     • Facilitare l’uso in modelli di machine learning che gestiscono feature categoriche\n",
    "\n",
    "3. Output informativo:\n",
    "   - Stampa un messaggio che conferma l’imputazione e la conversione a categoria.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(comment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f1b5925b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Imputazione Na/vuoti in 'notes' con 'no_tone' e conversione a categoria.\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Colonna 'notes' (Categorica - Imputazione a 'no_tone')\n",
    "df['notes'] = df['notes'].replace('', 'no_tone').fillna('no_tone')\n",
    "df['notes'] = df['notes'].astype('category')\n",
    "print(\" - Imputazione Na/vuoti in 'notes' con 'no_tone' e conversione a categoria.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
